{"id": "2602.11398", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.11398", "abs": "https://arxiv.org/abs/2602.11398", "authors": ["Hormoz Shahrzad", "Niharika Gajawell", "Kaitlin Maile", "Manish Saggar", "Risto Miikkulainen"], "title": "Evolution With Purpose: Hierarchy-Informed Optimization of Whole-Brain Models", "comment": null, "summary": "Evolutionary search is well suited for large-scale biophysical brain modeling, where many parameters with nonlinear interactions and no tractable gradients need to be optimized. Standard evolutionary approaches achieve an excellent fit to MRI data; however, among many possible such solutions, it finds ones that overfit to individual subjects and provide limited predictive power. This paper investigates whether guiding evolution with biological knowledge can help. Focusing on whole-brain Dynamic Mean Field (DMF) models, a baseline where 20 parameters were shared across the brain was compared against a heterogeneous formulation where different sets of 20 parameters were used for the seven canonical brain regions. The heterogeneous model was optimized using four strategies: optimizing all parameters at once, a curricular approach following the hierarchy of brain networks (HICO), a reversed curricular approach, and a randomly shuffled curricular approach. While all heterogeneous strategies fit the data well, only curricular approaches generalized to new subjects. Most importantly, only HICO made it possible to use the parameter sets to predict the subjects' behavioral abilities as well. Thus, by guiding evolution with biological knowledge about the hierarchy of brain regions, HICO demonstrated how domain knowledge can be harnessed to serve the purpose of optimization in real-world domains."}
{"id": "2602.11209", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.11209", "abs": "https://arxiv.org/abs/2602.11209", "authors": ["Ziyi Yang", "Kalit Inani", "Keshav Kabra", "Vima Gupta", "Anand Padmanabha Iyer"], "title": "SAFuzz: Semantic-Guided Adaptive Fuzzing for LLM-Generated Code", "comment": "11 pages, 6 figures, 4 tables", "summary": "While AI-coding assistants accelerate software development, current testing frameworks struggle to keep pace with the resulting volume of AI-generated code. Traditional fuzzing techniques often allocate resources uniformly and lack semantic awareness of algorithmic vulnerability patterns, leading to inefficient resource usage and missed vulnerabilities. To address these limitations, we present a hybrid testing framework that leverages LLM-guided adaptive fuzzing to detect algorithmic vulnerabilities efficiently. Our system SAFuzz integrates prompt-based behavioral diversification, harness generation with problem-specific oracles, and an LLM-based predictor to enable adaptive resource allocation and dynamic early stopping. Evaluating SAFuzz on CSES algorithmic problems, we improve vulnerability discrimination precision from 77.9% to 85.7% and achieve a 1.71x reduction in time cost compared to SOTA GreenFuzz while maintaining comparable recall. We further observe that combining our approach with existing unit test generation methods yields complementary gains, increasing the bug detection recall from 67.3% to 79.5%."}
{"id": "2602.11235", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11235", "abs": "https://arxiv.org/abs/2602.11235", "authors": ["Xin Song", "Zhilin Guan", "Ruidong Han", "Binghao Tang", "Tianwen Chen", "Bing Li", "Zihao Li", "Han Zhang", "Fei Jiang", "Chaolin Xie", "Chi Ma", "Chunyang Jiang", "Chunzhen Jing", "Dengxuan Li", "Fengyi Li", "Lei Yu", "Mengyao Sun", "Pu Wang", "Qing Wang", "Rui Fan", "Shangyu Chen", "Shifeng Du", "Siyuan Bai", "Wei Lin", "Wentao Zhu", "Zhou Han", "Zhuo Chen", "Zikang Xu"], "title": "MTFM: A Scalable and Alignment-free Foundation Model for Industrial Recommendation in Meituan", "comment": null, "summary": "Industrial recommendation systems typically involve multiple scenarios, yet existing cross-domain (CDR) and multi-scenario (MSR) methods often require prohibitive resources and strict input alignment, limiting their extensibility. We propose MTFM (Meituan Foundation Model for Recommendation), a transformer-based framework that addresses these challenges. Instead of pre-aligning inputs, MTFM transforms cross-domain data into heterogeneous tokens, capturing multi-scenario knowledge in an alignment-free manner. To enhance efficiency, we first introduce a multi-scenario user-level sample aggregation that significantly enhances training throughput by reducing the total number of instances. We further integrate Grouped-Query Attention and a customized Hybrid Target Attention to minimize memory usage and computational complexity. Furthermore, we implement various system-level optimizations, such as kernel fusion and the elimination of CPU-GPU blocking, to further enhance both training and inference throughput. Offline and online experiments validate the effectiveness of MTFM, demonstrating that significant performance gains are achieved by scaling both model capacity and multi-scenario training data."}
{"id": "2602.11330", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.11330", "abs": "https://arxiv.org/abs/2602.11330", "authors": ["Sushmita Gupta", "Pallavi Jain", "Sanjay Seetharaman", "Meirav Zehavi"], "title": "When agents choose bundles autonomously: guarantees beyond discrepancy", "comment": "40 pages; abstract shortened due to arXiv requirements", "summary": "We consider the fair division of indivisible items among $n$ agents with additive non-negative normalized valuations, with the goal of obtaining high value guarantees, that is, close to the proportional share for each agent.\n  We prove that partitions where \\emph{every} part yields high value for each agent are asymptotically limited by a discrepancy barrier of $Θ(\\sqrt{n})$. Guided by this, our main objective is to overcome this barrier and achieve stronger individual guarantees for each agent in polynomial time.\n  Towards this, we are able to exhibit an exponential improvement over the discrepancy barrier. In particular, we can create partitions on-the-go such that when agents arrive sequentially (representing a previously-agreed priority order) and pick a part autonomously and rationally (i.e., one of highest value), then each is guaranteed a part of value at least $\\mathsf{PROP} - \\mathcal{O}{(\\log n)}$. Moreover, we show even better guarantees for three restricted valuation classes such as those defined by: a common ordering on items, a bound on the multiplicity of values, and a hypergraph with a bound on the \\emph{influence} of any agent. Specifically, we study instances where: (1) the agents are ``close'' to unanimity in their relative valuation of the items -- a generalization of the ordered additive setting; (2) the valuation functions do not assign the same positive value to more than $t$ items; and (3) the valuation functions respect a hypergraph, a setting introduced by Christodoulou et al. [EC'23], where agents are vertices and items are hyperedges. While the sizes of the hyperedges and neighborhoods can be arbitrary, the influence of any agent $a$, defined as the number of its neighbors who value at least one item positively that $a$ also values positively, is bounded."}
{"id": "2602.11400", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11400", "abs": "https://arxiv.org/abs/2602.11400", "authors": ["Paula Böhm", "Robert Bredereck", "Till Fluschnik"], "title": "Maximizing Index Diversity in Committee Elections", "comment": "A short version was published in the proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "We introduce two models of multiwinner elections with approval preferences and labelled candidates that take the committee's diversity into account. One model aims to find a committee with maximal diversity given a scoring function (e.g. of a scoring-based voting rule) and a lower bound for the score to be respected. The second model seeks to maximize the diversity given a minimal satisfaction for each agent to be respected. To measure the diversity of a committee, we use multiple diversity indices used in ecology and introduce one new index. We define (desirable) properties of diversity indices, test the indices considered against these properties, and characterize the new index. We analyze the computational complexity of computing a committee for both models and scoring functions of well-known voting rules, and investigate the influence of weakening the score or satisfaction constraints on the diversity empirically."}
{"id": "2602.11404", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.11404", "abs": "https://arxiv.org/abs/2602.11404", "authors": ["Ioannis Caragiannis", "Vasilis Gkatzelis", "Sebastian Homrighausen"], "title": "The Distortion of Prior-Independent b-Matching Mechanisms", "comment": null, "summary": "In a setting where $m$ items need to be partitioned among $n$ agents, we evaluate the performance of mechanisms that take as input each agent's \\emph{ordinal preferences}, i.e., their ranking of the items from most- to least-preferred. The standard measure for evaluating ordinal mechanisms is the \\emph{distortion}, and the vast majority of the literature on distortion has focused on worst-case analysis, leading to some overly pessimistic results. We instead evaluate the distortion of mechanisms with respect to their expected performance when the agents' preferences are generated stochastically. We first show that no ordinal mechanism can achieve a distortion better than $e/(e-1)\\approx 1.582$, even if each agent needs to receive exactly one item (i.e., $m=n$) and every agent's values for different items are drawn i.i.d.\\ from the same known distribution. We then complement this negative result by proposing an ordinal mechanism that achieves the optimal distortion of $e/(e-1)$ even if each agent's values are drawn from an agent-specific distribution that is unknown to the mechanism. To further refine our analysis, we also optimize the \\emph{distortion gap}, i.e., the extent to which an ordinal mechanism approximates the optimal distortion possible for the instance at hand, and we propose a mechanism with a near-optimal distortion gap of $1.076$. Finally, we also evaluate the distortion and distortion gap of simple mechanisms that have a one-pass structure."}
